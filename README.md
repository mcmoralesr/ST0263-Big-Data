# Proyecto 3 ‚Äì An√°lisis de Clima y Movilidad con Spark y AWS EMR - BIG DATA

## Informaci√≥n del curso
Materia: ST0263 - T√≥picos Especiales en Telem√°tica  
Estudiantes:  
- Manuel Arango G√≥mez - marangog3@eafit.edu.co  
- Sebasti√°n Cano Rinc√≥n - scanor2@eafit.edu.co  
- Maria Camila Morales - mcmorales@eafit.edu.co  
Profesor: Alvaro Enrique Ospina Sanjuan - aeospinas@eafit.brightspace.com

## Nombre del proyecto

**An√°lisis de la relaci√≥n entre condiciones clim√°ticas y movilidad urbana en San Francisco**

---

## 1. Descripci√≥n de la actividad

An√°lisis cruzado entre datos clim√°ticos hist√≥ricos (Meteostat API) y datos de movilidad (Uber Movement) mediante arquitectura Big Data Batch sobre AWS.

### 1.1 Requerimientos cumplidos

- Captura autom√°tica de datos desde API (Meteostat) y archivos (Uber).
- Ingesta autom√°tica a S3 (zona raw).
- ETL automatizado en Spark sobre EMR (zona trusted).
- An√°lisis descriptivo con SparkSQL y SparkML (zona refined).
- Consulta de resultados por Athena y API Gateway.
- Automatizaci√≥n completa del pipeline con scripts.

![image](https://github.com/user-attachments/assets/de184001-a6d6-4ed0-9a3d-f1ef8ba864ad)


## 2. Dise√±o de alto nivel / arquitectura

Arquitectura batch en AWS:
- **S3**: almacenamiento por zonas (raw, trusted, refined)
- **EMR + Spark**: procesamiento ETL y anal√≠tico
- **Athena + API Gateway**: consulta de resultados
- **Base de datos relacional simulada**: Postgres en EC2 o RDS

---

## 3. Ambiente de desarrollo

- Lenguaje: Python 3.11
- Librer√≠as:
  - `boto3`, `pandas`, `requests`, `pyspark`
- Configuraci√≥n:
  - `.env` para API keys y credenciales AWS
  - Scripts:
    - `ingest_meteostat.py`
    - `upload_uber.py`
    - `extract_db.py`
    - `etl_spark.py`
    - `etl_spark_multi_year.py`
    - `analyze_spark.py`
    - `deploy_emr_cluster.py`

## 4. Ambiente de EJECUCI√ìN (producci√≥n)

Infraestructura:
- AWS S3, EMR, Athena, API Gateway

Configuraci√≥n:
- Bucket: `s3://proyecto3bigdata/`
- Variables de entorno: `.env`

Gu√≠a de ejecuci√≥n en el nodo principal EMR:

```
# Entrar por SSH
ssh -i ~/labsuser.pem hadoop@<master-public-dns>

# Ir al repo local
cd ~/etl_run/ST0263-Big-Data/spark_jobs

# Lanzar ETL simple
spark-submit --deploy-mode client etl_spark.py > etl_output.log 2>&1

# Lanzar ETL multi-a√±o
spark-submit --deploy-mode client etl_spark_multi_year.py > multi_etl_output.log 2>&1

# Verificar resultados
aws s3 ls s3://proyecto3bigdata/trusted/joined_weather_uber/
aws s3 ls s3://proyecto3bigdata/trusted/joined_weather_uber_multiyear/
```

---

## 5. Resultados esperados

- Parquet resultantes en `trusted/` con join de datos Uber + Meteo
- Dashboards consultables v√≠a Athena y/o scripts con Spark

5. Ejecuci√≥n del ETL Multi-Year en EMR
Este script realiza la uni√≥n entre m√∫ltiples archivos hist√≥ricos del clima (1973-2022) con los datos de movilidad de Uber para San Francisco. Guarda el resultado como Parquet en la zona trusted.

üìÅ Script utilizado


etl_spark_multi_year.py
üìå Comando de ejecuci√≥n desde el nodo principal del cluster EMR


spark-submit etl_spark_multi_year.py
üéØ Output esperado
Archivo Parquet en:

pgsql

s3://proyecto3bigdata/trusted/joined_weather_uber_multiyear/
‚úÖ Validaci√≥n
Puedes validar la escritura del parquet ejecutando el validador:


spark-submit validate_parquet.py

Este script:

Muestra el n√∫mero de filas

Imprime las primeras 10 filas

Imprime el esquema

![image](https://github.com/user-attachments/assets/16238f43-5f26-45f8-8380-39d05250ce0a)



## Resumen de hallazgos

Tras realizar el cruce de datos entre tiempos de viaje (Uber Movement) y temperatura promedio (Meteostat) en San Francisco, se obtuvieron los siguientes hallazgos para el a√±o con datos disponibles (2017):

| A√±o  | Tiempo Promedio de Viaje (s) | Temperatura Promedio (¬∞C) |
|------|-------------------------------|----------------------------|
| 2017 | 1702.34                       | 14.97                      |

Esto indica que en condiciones clim√°ticas templadas, los viajes promedio en ciertos sectores de la ciudad superaron los **28 minutos** en trayectos representativos.

---

## Comando de consulta en Athena

```sql
-- Promedio de temperatura y tiempo de viaje por a√±o
SELECT
  year,
  ROUND(AVG(CAST("Mean Travel Time (Seconds)" AS DOUBLE)), 2) AS avg_travel_time,
  ROUND(AVG(avg_temp), 2) AS avg_temp
FROM
  proyecto3.joined_weather_uber_multiyear
GROUP BY
  year
ORDER BY
  year;
```

---

## Validaci√≥n de resultados con PySpark (opcional)

```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("ValidateParquet").getOrCreate()

df = spark.read.parquet("s3://proyecto3bigdata/trusted/joined_weather_uber_multiyear/")
print("N√∫mero total de filas:", df.count())
df.show(10)
df.printSchema()

spark.stop()
```

---

## Archivo origen

- **Tabla analizada**: `proyecto3.joined_weather_uber_multiyear`
- **Ubicaci√≥n S3**: `s3://proyecto3bigdata/trusted/joined_weather_uber_multiyear/`
![image](https://github.com/user-attachments/assets/64434e62-55e0-41a3-903d-1255b59754cc)


## 6. Problemas encontrados

- Falta de permisos IAM para lanzar steps EMR

![image](https://github.com/user-attachments/assets/f686c2a5-a440-4762-9e17-0cfaeda02fb0)

- Soluci√≥n: ejecuci√≥n manual desde nodo maestro por SSH
